{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f420238f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adam/phd/recurrent-graph-autoencoder\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e511f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb8b0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from rga.data.diag_repr_graph_data_module import DiagonalRepresentationGraphDataModule\n",
    "from rga.data.graph_loaders import RealGraphLoader, SyntheticGraphLoader\n",
    "from rga.experiments.decorators import add_graphloader_args\n",
    "from rga.models.autoencoder_components import GraphEncoder\n",
    "from rga.models.edge_encoders import MemoryEdgeEncoder\n",
    "from rga.util.load_model import *\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6fd2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealSaver(DiagonalRepresentationGraphDataModule):\n",
    "    graphloader_class = RealGraphLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8592e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_split = [0.7, 0.15, 0.15]\n",
    "train_val_test_permutation_split = [1, 0, 0.0]\n",
    "num_dataset_graph_permutations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d8484d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully loaded!\n",
      "File path: ./datasets/imdb_multi_labels.pkl\n",
      "Statistic of set:  Train dataset\n",
      "             Dataset size : 1050\n",
      "                   Labels : True\n",
      "           Min node count : 7\n",
      "       Average node count : 12.89\n",
      "           Max node count : 78\n",
      "           Min edge count : 12.0\n",
      "       Average edge count : 64.18\n",
      "           Max edge count : 982.0\n",
      "     Min filling fraction : 0.13\n",
      " Average filling fraction : 0.78\n",
      "     Max filling fraction : 1.0\n",
      "          Label \"1\" count : 342\n",
      "          Label \"2\" count : 340\n",
      "          Label \"3\" count : 368\n",
      "----------------------------------------------------------------\n",
      "Statistic of set:  Validation dataset 0\n",
      "             Dataset size : 225\n",
      "                   Labels : True\n",
      "           Min node count : 7\n",
      "       Average node count : 13.6\n",
      "           Max node count : 89\n",
      "           Min edge count : 12.0\n",
      "       Average edge count : 73.44\n",
      "           Max edge count : 1467.0\n",
      "     Min filling fraction : 0.14\n",
      " Average filling fraction : 0.74\n",
      "     Max filling fraction : 1.0\n",
      "          Label \"1\" count : 85\n",
      "          Label \"2\" count : 77\n",
      "          Label \"3\" count : 63\n",
      "----------------------------------------------------------------\n",
      "Statistic of set:  Test dataset 0\n",
      "             Dataset size : 225\n",
      "                   Labels : True\n",
      "           Min node count : 7\n",
      "       Average node count : 12.93\n",
      "           Max node count : 63\n",
      "           Min edge count : 12.0\n",
      "       Average edge count : 66.63\n",
      "           Max edge count : 703.0\n",
      "     Min filling fraction : 0.14\n",
      " Average filling fraction : 0.8\n",
      "     Max filling fraction : 1.0\n",
      "          Label \"1\" count : 73\n",
      "          Label \"2\" count : 83\n",
      "          Label \"3\" count : 69\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a42f52aa30a44d391ea4e5c7b54df8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preparing dataset train for autoencoder:   0%|          | 0/1050 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c391e91aece74c9cae3b2b401248e66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preparing dataset val 0 for autoencoder:   0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10f111f5604414eb7d35653e5928f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preparing dataset test 0 for autoencoder:   0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = RealSaver(\n",
    "    pickled_dataset_path='./datasets/imdb_multi_labels.pkl',\n",
    "    use_labels=True,\n",
    "    bfs=True,\n",
    "    deduplicate_train = False,\n",
    "    deduplicate_val_test = False,\n",
    "    batch_size=500000,\n",
    "    batch_size_val=500000,\n",
    "    batch_size_test=500000,\n",
    "    workers=0,\n",
    "    block_size=8,\n",
    "    subgraph_scheduler_name='none',\n",
    "    subgraph_scheduler_params={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "737506ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = 'tb_logs/RecursiveGraphAutoencoder/version_8/checkpoints/epoch=77-step=1325-v1.ckpt'\n",
    "hparams_path = 'tb_logs/RecursiveGraphAutoencoder/version_8/hparams.yaml'\n",
    "hparams = load_hparams(hparams_path)\n",
    "encoder = GraphEncoder(edge_encoder_class = MemoryEdgeEncoder, **hparams)\n",
    "\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "encoder_checkpoint = {\n",
    "    k.replace(\"encoder.edge_encoder.\", \"edge_encoder.\"): v\n",
    "    for (k, v) in checkpoint[\"state_dict\"].items()\n",
    "    if \"encoder\" in k\n",
    "}\n",
    "encoder.load_state_dict(encoder_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bae821b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rga.models.classifier_components import MLPClassifier\n",
    "classifier_checkpoint_model = MLPClassifier(**hparams)\n",
    "\n",
    "classifier_checkpoint = {\n",
    "    k.replace(\"classifier.nn.\", \"nn.\"): v\n",
    "    for (k, v) in checkpoint[\"state_dict\"].items()\n",
    "    if \"class\" in k\n",
    "}\n",
    "\n",
    "classifier_checkpoint_model.load_state_dict(classifier_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9adace3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cca36863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050\n",
      "225\n",
      "225\n"
     ]
    }
   ],
   "source": [
    "train_batch = next(iter(dataset.train_dataloader()))\n",
    "train_batch_labels = train_batch[3]\n",
    "print(len(train_batch_labels))\n",
    "\n",
    "val_batch = next(iter(dataset.val_dataloader()[0]))\n",
    "val_batch_labels = val_batch[3]\n",
    "print(len(val_batch_labels))\n",
    "\n",
    "test_batch = next(iter(dataset.test_dataloader()[0]))\n",
    "test_batch_labels = test_batch[3]\n",
    "print(len(test_batch_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a69f4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_X = encoder(train_batch).detach().numpy()\n",
    "val_batch_X = encoder(val_batch).detach().numpy()\n",
    "test_batch_X = encoder(test_batch).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7064650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier_checkpoint_model(torch.tensor(val_batch_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6ccfff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.27      0.35        85\n",
      "           1       0.44      0.61      0.51        77\n",
      "           2       0.48      0.54      0.51        63\n",
      "\n",
      "    accuracy                           0.46       225\n",
      "   macro avg       0.47      0.47      0.46       225\n",
      "weighted avg       0.47      0.46      0.45       225\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/Oprogramowanie/anaconda3/envs/rga/lib/python3.9/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "pred_val = torch.argmax(classifier_checkpoint_model(torch.tensor(val_batch_X)), dim=1)\n",
    "print(classification_report(val_batch_labels-1, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6d166cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from torch import nn\n",
    "from rga.models.utils.layers import sequential_from_layer_sizes\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "class EmbeddingAE(LightningModule):\n",
    "    def __init__(self, embedding_size, layers):\n",
    "        super().__init__()\n",
    "        self.compressing_layer = torch.argmin(torch.tensor(layers))\n",
    "        self.nn = sequential_from_layer_sizes(embedding_size, embedding_size, layers)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.nn(x)\n",
    "\n",
    "    def get_compressed_embeddings(self, x):\n",
    "        return self.nn[:self.compressing_layer*2+1](x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.loss(batch, self(batch))\n",
    "        self.log(\"loss/train\", loss, on_step=True, on_epoch=False, prog_bar=True, logger=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.loss(batch, self(batch))\n",
    "        self.log(\"loss/val\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=False)\n",
    "        return loss\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7abb35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch_lightning as pl\n",
    "# from torch import nn\n",
    "# import torch\n",
    "\n",
    "\n",
    "\n",
    "# class VAE(pl.LightningModule):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # self.save_hyperparameters()\n",
    "\n",
    "#         # encoder, decoder\n",
    "#         self.encoder = sequential_from_layer_sizes(256, 32, [128, 64])\n",
    "#         self.decoder = sequential_from_layer_sizes(16, 256, [32, 64, 128])\n",
    "#         self.loss = nn.MSELoss()\n",
    "#         # distribution parameters\n",
    "#         self.fc_mu = nn.Linear(32, 16)\n",
    "#         self.fc_var = nn.Linear(32, 16)\n",
    "\n",
    "#         # for the gaussian likelihood\n",
    "#         self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "#     def gaussian_likelihood(self, x_hat, logscale, x):\n",
    "#         scale = torch.exp(logscale)\n",
    "#         mean = x_hat\n",
    "#         dist = torch.distributions.Normal(mean, scale)\n",
    "\n",
    "#         # measure prob of seeing image under p(x|z)\n",
    "#         log_pxz = dist.log_prob(x)\n",
    "#         return log_pxz.sum(dim=(1, 2, 3))\n",
    "\n",
    "#     def kl_divergence(self, z, mu, std):\n",
    "#         # --------------------------\n",
    "#         # Monte carlo KL divergence\n",
    "#         # --------------------------\n",
    "#         # 1. define the first two probabilities (in this case Normal for both)\n",
    "#         p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "#         q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "#         # 2. get the probabilities from the equation\n",
    "#         log_qzx = q.log_prob(z)\n",
    "#         log_pz = p.log_prob(z)\n",
    "\n",
    "#         # kl\n",
    "#         kl = (log_qzx - log_pz)\n",
    "#         kl = kl.sum(-1)\n",
    "#         return kl\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         x = batch\n",
    "\n",
    "#         # encode x to get the mu and variance parameters\n",
    "#         x_encoded = self.encoder(x)\n",
    "#         mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
    "\n",
    "#         # sample z from q\n",
    "#         std = torch.exp(log_var / 2)\n",
    "#         q = torch.distributions.Normal(mu, std)\n",
    "#         z = q.rsample()\n",
    "\n",
    "#         # decoded\n",
    "#         x_hat = self.decoder(z)\n",
    "\n",
    "#         # reconstruction loss\n",
    "#         recon_loss = self.loss(x_hat, x)#self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
    "\n",
    "#         # kl\n",
    "#         kl = self.kl_divergence(z, mu, std)\n",
    "\n",
    "#         # elbo\n",
    "#         elbo = (kl - recon_loss)\n",
    "#         elbo = elbo.mean()\n",
    "\n",
    "#         self.log_dict({\n",
    "#             'elbo': elbo,\n",
    "#             'kl': kl.mean(),\n",
    "#             'recon_loss': recon_loss.mean(),\n",
    "#             'reconstruction': recon_loss.mean(),\n",
    "#             'kl': kl.mean(),\n",
    "#         })\n",
    "\n",
    "#         return elbo\n",
    "\n",
    "#     def get_compressed_embeddings(self, batch):\n",
    "#         x_encoded = self.encoder(batch)\n",
    "#         return self.fc_mu(x_encoded)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ae = VAE()#EmbeddingAE(256, [128, 64, 32, 16, 32, 64, 128])\n",
    "# from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# dataloaders_ae = {\n",
    "#     'train':DataLoader(train_batch_X, batch_size=32, num_workers=0),\n",
    "#     'val':DataLoader(val_batch_X, batch_size=32, num_workers=0),\n",
    "#     'test':DataLoader(test_batch_X, batch_size=32, num_workers=0)\n",
    "# }\n",
    "\n",
    "\n",
    "# trainer = Trainer(max_epochs=50, log_every_n_steps=5) #, callbacks=[EarlyStopping(monitor=\"loss/val\")]\n",
    "# trainer.fit(ae, train_dataloaders=dataloaders_ae.get('train'), val_dataloaders=dataloaders_ae.get('val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb58cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_batch_X_compressed = ae.get_compressed_embeddings(torch.tensor(train_batch_X)).detach().numpy()\n",
    "# val_batch_X_compressed = ae.get_compressed_embeddings(torch.tensor(val_batch_X)).detach().numpy()\n",
    "# test_batch_X_compressed = ae.get_compressed_embeddings(torch.tensor(test_batch_X)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8ed08fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_batch_X_compressed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5665ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adb01831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | loss_function | CrossEntropyLoss | 0     \n",
      "1 | metrics_train | ModuleList       | 0     \n",
      "2 | metrics_val   | ModuleList       | 0     \n",
      "3 | metrics_test  | ModuleList       | 0     \n",
      "4 | gru           | GRU              | 33.1 K\n",
      "5 | nn            | Sequential       | 21.9 K\n",
      "---------------------------------------------------\n",
      "55.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.0 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8178bd80334748ff9975955bf31e2493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/Oprogramowanie/anaconda3/envs/rga/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:116: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/adam/Oprogramowanie/anaconda3/envs/rga/lib/python3.9/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "/home/adam/Oprogramowanie/anaconda3/envs/rga/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:412: UserWarning: The number of training samples (33) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e7297b086f4c52a355c050ad5efe31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d37b3dffb142aaae2b2ba9c2dbcfb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18337aa341384224b2945f010bee8fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff84e62e6ad4461d9ea52ebadca85ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d235cd2a9294b52b9f84c711bd16d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdd45e500c245dabda81b745f172eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45afc7b082e47d9b7d6060caf39bcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cfb549b944d443c9d71a2bd03e10d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2202aab93cd94ab7aea232b83b1bf55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a04d99c57743b8a637051e17ca1827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca26c4e9cfd548faa3d26068547bf6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b395b0cd9c04dc482743d9cbdac6c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454f931015f140bc8e0dfcaccb074c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b70fdd213248b5bdf4f4c1a377d5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb49bfdbe8a450ba2eb4da3dbf7e41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980ca3b40bdf4aebbc255c3ee5809f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bd960d94414031a8a32ed80816f71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded2a5c9ccb7433399d22afc7d7198d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c17ae5046c4a88a34b710c0f3403a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defa5a7a8ba1427a876d42cf0bed7274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e79e83168c47579cdaec4b76aecc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from torch import nn\n",
    "from rga.models.utils.layers import sequential_from_layer_sizes\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Trainer\n",
    "from rga.models.base import BaseModel\n",
    "from rga.models.utils.getters import * \n",
    "\n",
    "class EmbeddingClassifier(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size: int,\n",
    "        class_count: int,\n",
    "        classifier_hidden_layer_sizes,\n",
    "        classifier_activation_function: str,\n",
    "        classifier_dropout: float,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding_size = embedding_size\n",
    "        input_size = embedding_size\n",
    "\n",
    "        activation_f = get_activation_function(classifier_activation_function)\n",
    "        self.class_count = class_count\n",
    "        output_function = nn.Sigmoid if class_count == 2 else nn.Softmax\n",
    "\n",
    "        self.gru_depth = 8\n",
    "\n",
    "        self.gru = torch.nn.GRU(\n",
    "            input_size = 0,\n",
    "            hidden_size = embedding_size,\n",
    "            num_layers = 1,\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        self.nn = sequential_from_layer_sizes(\n",
    "            input_size,\n",
    "            class_count if class_count != 2 else 1,\n",
    "            classifier_hidden_layer_sizes,\n",
    "            activation_f,\n",
    "            output_function=output_function,\n",
    "            dropout=classifier_dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, graphs: Tensor) -> Tensor:\n",
    "        gru_in = torch.empty(size=[graphs.shape[0], self.gru_depth, 0])\n",
    "        gru_h_0 = graphs[None, :, :]\n",
    "        gru_out, gru_hidden = self.gru(gru_in, gru_h_0)\n",
    "        graphs = gru_hidden[0]\n",
    "\n",
    "        return self.nn(graphs)\n",
    "\n",
    "    def step(self, batch, metrics: List = []) -> Tensor:\n",
    "        y_pred = self(batch[:, :-1])\n",
    "        labels = (batch[:, -1] - 1).long()\n",
    "\n",
    "        if self.class_count == 2:\n",
    "            loss = self.loss_function(y_pred[:, 0], labels.float())\n",
    "            y_pred_labels = torch.round(y_pred[:, 0]).int()\n",
    "        else:\n",
    "            loss = self.loss_function(y_pred, labels)\n",
    "            y_pred_labels = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "        for metric in metrics:\n",
    "            metric(y_pred_labels, labels)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "model = EmbeddingClassifier(\n",
    "    embedding_size = 104, \n",
    "    class_count = 3, \n",
    "    classifier_hidden_layer_sizes = [128, 64], \n",
    "    classifier_activation_function = 'ReLU', \n",
    "    classifier_dropout = 0.1, \n",
    "    loss_function='CrossEntropy',\n",
    "    metrics=['Accuracy'],\n",
    "    metric_update_interval=1,\n",
    "    lr = 0.0001\n",
    ")\n",
    "\n",
    "data_loader_embedding_classifier = DataLoader(torch.cat([torch.tensor(train_batch_X), train_batch_labels[:, None]], axis = 1), batch_size=32)\n",
    "data_loader_val_embedding_classifier = DataLoader(torch.cat([torch.tensor(val_batch_X), val_batch_labels[:, None]], axis = 1), batch_size=32)\n",
    "\n",
    "\n",
    "trainer = Trainer(max_epochs = 100, check_val_every_n_epoch=5,)\n",
    "trainer.fit(model, train_dataloaders=data_loader_embedding_classifier, val_dataloaders=data_loader_val_embedding_classifier)\n",
    "# trainer.test(model, dataloaders=data_loader_val_embedding_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ce02490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.33      0.39        85\n",
      "           1       0.45      0.58      0.51        77\n",
      "           2       0.51      0.54      0.52        63\n",
      "\n",
      "    accuracy                           0.48       225\n",
      "   macro avg       0.48      0.48      0.47       225\n",
      "weighted avg       0.48      0.48      0.47       225\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/Oprogramowanie/anaconda3/envs/rga/lib/python3.9/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "pred_val = torch.argmax(model(torch.tensor(val_batch_X)), dim=1)\n",
    "print(classification_report(val_batch_labels-1, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0933e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "524db657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.48      0.62       342\n",
      "           2       0.61      0.78      0.69       340\n",
      "           3       0.62      0.74      0.67       368\n",
      "\n",
      "    accuracy                           0.67      1050\n",
      "   macro avg       0.71      0.66      0.66      1050\n",
      "weighted avg       0.71      0.67      0.66      1050\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.28      0.36        85\n",
      "           2       0.43      0.60      0.50        77\n",
      "           3       0.51      0.59      0.55        63\n",
      "\n",
      "    accuracy                           0.48       225\n",
      "   macro avg       0.49      0.49      0.47       225\n",
      "weighted avg       0.49      0.48      0.46       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sklearn_model = RandomForestClassifier(n_estimators=500, min_samples_leaf=5, min_samples_split=4)\n",
    "sklearn_model = GradientBoostingClassifier(min_samples_leaf=5, min_samples_split=4)\n",
    "# sklearn_model = SVC()\n",
    "# sklearn_model = MLPClassifier(hidden_layer_sizes=[16, 16, 16, 16, 16, 16], random_state=1,max_iter=500)\n",
    "sklearn_model.fit(train_batch_X, train_batch_labels)\n",
    "train_batch_labels_pred = sklearn_model.predict(train_batch_X)\n",
    "print(classification_report(train_batch_labels, train_batch_labels_pred))\n",
    "\n",
    "val_batch_labels_pred = sklearn_model.predict(val_batch_X)\n",
    "print(classification_report(val_batch_labels, val_batch_labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e38776c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c37224fb4409952eb251e31ba483053a30ac3ecaa917b50e887cf90f0c69f7d5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
